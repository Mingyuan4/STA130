{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7f5679b",
   "metadata": {},
   "source": [
    "### Chatbot Session:\n",
    "\n",
    "https://chatgpt.com/share/673d374e-74f8-800d-95f1-c425a7d29559"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e1ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Questioin 1\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeda10b",
   "metadata": {},
   "source": [
    "a) Type of Problem and Real-World Applications\n",
    "\n",
    "A Classification Decision Tree solves classification problems, where the goal is to predict a category or class (e.g., \"Yes\" or \"No\"). It splits data into smaller groups based on decision rules, which are organized in a tree-like structure. This method is useful in real-world applications like diagnosing diseases (e.g., \"Diabetic\" or \"Non-Diabetic\"), detecting fraud (e.g., \"Fraud\" or \"No Fraud\"), customer segmentation (e.g., frequent vs. occasional shoppers), and making product recommendations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54998ff",
   "metadata": {},
   "source": [
    "b) Difference in Predictions: Decision Tree vs. Linear Regression\n",
    "\n",
    "A Classification Decision Tree predicts a class by dividing the data into groups based on decision rules, continuing until most data in each group belongs to one class. It outputs class labels (e.g., \"Spam\") or probabilities (e.g., 70% Spam, 30% Not Spam). In contrast, Multiple Linear Regression predicts a continuous number (e.g., house price) using a linear formula based on input features. While decision trees are used for classification tasks, linear regression is used for regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110615ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 2\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29de0510",
   "metadata": {},
   "source": [
    "Accuracy\n",
    "\n",
    "- What it measures: The overall correctness of a model, showing how many predictions (both positive and negative) were correct out of all predictions.\n",
    "- When to use: Best for balanced datasets where false positives and false negatives are equally important.\n",
    "- Example: Identifying defective products in a factory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986b062",
   "metadata": {},
   "source": [
    "Sensitivity (True Positive Rate)\n",
    "\n",
    "- What it measures: How good the model is at identifying positive cases (catching all the \"yes\" cases).\n",
    "- When to use: Critical when missing a positive case is costly, like in disease detection.\n",
    "- Example: Diagnosing cancer to catch all patients with the disease."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86985ca8",
   "metadata": {},
   "source": [
    "Specificity (True Negative Rate)\n",
    "\n",
    "- What it measures: How good the model is at identifying negative cases (catching all the \"no\" cases).\n",
    "- When to use: Important when false positives have serious consequences, like false accusations.\n",
    "- Example: Ensuring innocent people aren’t flagged as suspects in a crime."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1959f",
   "metadata": {},
   "source": [
    "Precision (Positive Predictive Value)\n",
    "\n",
    "- What it measures: How accurate the positive predictions are (how many of the \"yes\" predictions were actually correct).\n",
    "- When to use: Important when false positives are costly, like sending spam emails to a non-spam folder.\n",
    "- Example: Making sure flagged emails are truly spam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78ecdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 3\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36da7115",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, recall_score, make_scorer\n",
    "import graphviz as gv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/STA130_F23/main/Data/amazonbooks.csv\"\n",
    "ab = pd.read_csv(url, encoding=\"ISO-8859-1\")\n",
    "# create `ab_reduced_noNaN` based on the specs above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930ad779",
   "metadata": {},
   "source": [
    "## Amazon Books Dataset: Preprocessed and Analyzed\n",
    "\n",
    "### **Preprocessing Steps**\n",
    "1. Removed irrelevant columns: `Weight_oz`, `Width`, and `Height`.\n",
    "2. Dropped rows with missing values (`NaN` entries).\n",
    "3. Converted:\n",
    "   - `Pub year` and `NumPages` to integer.\n",
    "   - `Hard_or_Paper` to categorical.\n",
    "\n",
    "### **Dataset Overview**\n",
    "- **Total Entries**: 319\n",
    "- **Columns**: 10 (e.g., Title, Author, Prices, Pages, Year, etc.)\n",
    "- **Data Types**: Mixed (numerical, categorical, and textual)\n",
    "\n",
    "### **Key Findings**\n",
    "\n",
    "#### 1. **Pricing**\n",
    "- **Average List Price**: \\$18.36 (Range: \\$1.50–\\$139.95)\n",
    "- **Average Amazon Price**: \\$12.94 (Range: \\$0.77–\\$139.95)\n",
    "\n",
    "#### 2. **Physical Attributes**\n",
    "- **Number of Pages**: \n",
    "  - Median: 320 pages\n",
    "  - Range: 24–896 pages\n",
    "- **Thickness**:\n",
    "  - Median: 0.9 inches\n",
    "  - Range: 0.1–2.1 inches\n",
    "\n",
    "#### 3. **Categorical Breakdown**\n",
    "- **Format (`Hard_or_Paper`)**: \n",
    "  - Paperback: 73% (233 books)\n",
    "  - Hardcover: 27% (86 books)\n",
    "\n",
    "#### 4. **Publication Year**\n",
    "- Most books were published between 2000–2011.\n",
    "- **Peaks**: \n",
    "  - 2010: 39 books\n",
    "  - 2011: 52 books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5723af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 4\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25acdc7",
   "metadata": {},
   "source": [
    "\"The training set contains 255 observations, while the testing set contains 64 observations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba192a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the data into training (80%) and testing (20%) sets\n",
    "ab_reduced_noNaN_train, ab_reduced_noNaN_test = train_test_split(\n",
    "    ab_reduced_noNaN, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Reporting the sizes of each set\n",
    "train_count = len(ab_reduced_noNaN_train)\n",
    "test_count = len(ab_reduced_noNaN_test)\n",
    "\n",
    "print(f\"Training set size: {train_count}\")\n",
    "print(f\"Testing set size: {test_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02206694",
   "metadata": {},
   "source": [
    "The target variable (y) is Hard_or_Paper, converted to binary (1 for hardcover, 0 for paperback).\n",
    "\n",
    "The feature variable (X) is List Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801eb875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "y = pd.get_dummies(ab_reduced_noNaN_train[\"Hard_or_Paper\"])['H']  # Target variable\n",
    "X = ab_reduced_noNaN_train[['List Price']]  # Feature variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2987bb",
   "metadata": {},
   "source": [
    "\"A decision tree classifier was trained to predict the book type based on the List Price variable. The model uses a maximum depth of 2 to limit the complexity and overfitting.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21401442",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Training the decision tree model\n",
    "clf = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bdba1",
   "metadata": {},
   "source": [
    "\"The decision tree splits the List Price variable into intervals to predict whether a book is hardcover or paperback. Each node shows the split condition, the predicted class, and the number of samples in the node.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc7dfef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Visualizing the decision tree\n",
    "plt.figure(figsize=(10, 6))\n",
    "tree.plot_tree(clf, feature_names=['List Price'], class_names=['Paper', 'Hard'], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d237250",
   "metadata": {},
   "source": [
    "\"The decision tree creates thresholds for List Price to classify books. For example, if the List Price is below X, the book is classified as paperback.\"\n",
    "\n",
    "Include any specific thresholds from the tree."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6688dc",
   "metadata": {},
   "source": [
    "\"This analysis demonstrates how a decision tree can use a single numerical feature to make predictions and highlights the splits used to classify books into hardcover or paperback categories.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaf5af9",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "1. **Splitting the Dataset**:  \n",
    "   - The dataset was split into 80% training (255 observations) and 20% testing (64 observations) using `train_test_split`.\n",
    "\n",
    "2. **Preparing the Data**:  \n",
    "   - The target variable (`Hard_or_Paper`) was converted into binary (`1` for hardcover, `0` for paperback).  \n",
    "   - The feature used for prediction is `List Price`.\n",
    "\n",
    "3. **Training the Model**:  \n",
    "   - A decision tree classifier was trained with a maximum depth of 2 using only the `List Price` variable to predict the book type.\n",
    "\n",
    "4. **Visualizing the Tree**:  \n",
    "   - The decision tree shows thresholds for `List Price` that split the data into hardcover or paperback categories.  \n",
    "   - Example: If the `List Price` is below $15.50, the book is classified as paperback. If it's above $30, the book is classified as hardcover.\n",
    "\n",
    "This analysis demonstrates how the `List Price` variable can effectively predict whether a book is hardcover or paperback using a simple decision tree model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8838f02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 5\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a06fd4",
   "metadata": {},
   "source": [
    "The decision tree uses the features NumPages, Thick, and List Price to classify books as either hardcover or paperback, splitting the data at various thresholds for these features. Starting at the root, the tree evaluates one feature at a time, making splits based on conditions until it reaches a leaf node, where a prediction is made. For example, books with higher List Price or thicker dimensions are more likely to be classified as hardcover, while books with fewer pages or lower prices tend to be classified as paperback. With a maximum depth of 4, the tree captures meaningful patterns while avoiding overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 6\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e009f547",
   "metadata": {},
   "source": [
    "## Calculations for `clf` and `clf2`\n",
    "\n",
    "### **Model `clf` (Using `List Price` Only)**\n",
    "- **Sensitivity (True Positive Rate)**: 0.700  \n",
    "  - Proportion of hardcover books correctly predicted as hardcover.  \n",
    "  - Formula: \\( \\frac{\\text{TP}}{\\text{TP} + \\text{FN}} \\)  \n",
    "- **Specificity (True Negative Rate)**: 0.909  \n",
    "  - Proportion of paperback books correctly predicted as paperback.  \n",
    "  - Formula: \\( \\frac{\\text{TN}}{\\text{TN} + \\text{FP}} \\)  \n",
    "- **Accuracy**: 0.844  \n",
    "  - Overall proportion of correct predictions.  \n",
    "  - Formula: \\( \\frac{\\text{TP} + \\text{TN}}{\\text{Total Observations}} \\)  \n",
    "\n",
    "---\n",
    "\n",
    "### **Model `clf2` (Using `NumPages`, `Thick`, and `List Price`)**\n",
    "- **Sensitivity (True Positive Rate)**: 0.750  \n",
    "  - Proportion of hardcover books correctly predicted as hardcover.  \n",
    "- **Specificity (True Negative Rate)**: 0.909  \n",
    "  - Proportion of paperback books correctly predicted as paperback.  \n",
    "- **Accuracy**: 0.859  \n",
    "  - Overall proportion of correct predictions.  \n",
    "\n",
    "---\n",
    "\n",
    "### **Interpretation**\n",
    "- **`clf2` performs better** than `clf` due to higher sensitivity and accuracy, likely because it uses multiple features (`NumPages`, `Thick`, and `List Price`) to make predictions.  \n",
    "- Both models have the **same specificity** (0.909), meaning they are equally effective at identifying paperback books.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad19333",
   "metadata": {},
   "source": [
    "### Summarize the findings:\n",
    "\n",
    "Metrics for clf:\n",
    "\n",
    "- Sensitivity: 0.700\n",
    "- Specificity: 0.909\n",
    "- Accuracy: 0.844\n",
    "\n",
    "Metrics for clf2:\n",
    "\n",
    "- Sensitivity: 0.750\n",
    "- Specificity: 0.909\n",
    "- Accuracy: 0.859\n",
    "\n",
    "Interpretation:\n",
    "\n",
    "\"Both models perform well, but clf2 slightly outperforms clf in sensitivity and accuracy, likely because it uses more features (NumPages, Thick, and List Price) to make predictions. Both models have the same specificity, meaning they are equally good at identifying paperback books.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c676d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 7\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4582a2",
   "metadata": {},
   "source": [
    "The differences between the two confusion matrices are due to the features used in the models. The first matrix is based on a model (clf) that only uses List Price, which limits its ability to make accurate predictions. The second matrix is from a model (clf2) that uses more features (NumPages, Thick, and List Price), allowing it to capture more details and improve predictions. The confusion matrices for the test dataset (clf and clf2) are better because they show how the models perform on new, unseen data, which is a more reliable measure of their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269c369",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 8\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a06fc2d",
   "metadata": {},
   "source": [
    "Feature Importances for clf2\n",
    "\n",
    "The feature importances for the decision tree model (clf2) were calculated to understand which predictors contribute the most to the model's explanatory power. The most important predictor is List Price, with an importance score of 0.486, followed by Thick (0.297) and NumPages (0.217). These scores reflect the relative contributions of each feature to improving the model's predictions at various decision nodes. A visualization was created to illustrate these relative contributions clearly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7af1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Question 9\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bb492",
   "metadata": {},
   "source": [
    "In linear regression, interpreting coefficients is straightforward: each coefficient represents the change in the predicted value of the target variable for a one-unit increase in the corresponding predictor, holding all other predictors constant. In contrast, feature importances in decision trees represent the relative contribution of each predictor to improving the model’s performance (e.g., reducing Gini impurity or entropy) across all decision splits in the tree. While linear regression provides direct, additive relationships, decision trees capture complex, non-linear interactions, making feature importance more of a heuristic measure rather than a precise interpretation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af20699",
   "metadata": {},
   "source": [
    "In linear regression, interpreting coefficients is straightforward: each coefficient represents the change in the predicted value of the target variable for a one-unit increase in the corresponding predictor, holding all other predictors constant. In contrast, feature importances in decision trees represent the relative contribution of each predictor to improving the model’s performance (e.g., reducing Gini impurity or entropy) across all decision splits in the tree. While linear regression provides direct, additive relationships, decision trees capture complex, non-linear interactions, making feature importance more of a heuristic measure rather than a precise interpretation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
